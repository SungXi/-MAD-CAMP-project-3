{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log before main function\n",
      "train mode test mode\n",
      "Finished loading vgg19.npy\n",
      "Finished loading vgg19.npy\n",
      "Finished building vgg19: 0s\n",
      "Finished building vgg19: 0s\n",
      "Finished building model\n",
      "Finished loading data\n",
      "before pre train\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/zeros_66-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/zeros_66, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/zeros_66-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/zeros_66, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cc675cdb6962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Log before main function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Log after main function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cc675cdb6962>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;31m#     elif args.mode == 'test':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cc675cdb6962>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m                                                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcartoon_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcartoon_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                                                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblur_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mblur_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                                                                 self.is_train: True})\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-1.8.0\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/zeros_66-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/zeros_66, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import argparse\n",
    "import os\n",
    "import time\n",
    "import model\n",
    "import utils\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# def arg_parser():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--image_size\", default = 256, type = int)\n",
    "#     parser.add_argument(\"--crop_size\", default = 70, type = int)\n",
    "#     parser.add_argument(\"--batch_size\", default = 128, type = int)     \n",
    "#     parser.add_argument(\"--pre_train_iter\", default = 20000, type = int)\n",
    "#     parser.add_argument(\"--iter\", default = 100000, type = int)\n",
    "#     parser.add_argument(\"--learning_rate\", default = 1e-4, type = float)\n",
    "#     parser.add_argument(\"--gpu_fraction\", default = 0.5, type = float)\n",
    "#     parser.add_argument(\"--save_dir\", default = 'saved_models')\n",
    "#     parser.add_argument(\"--train_out_dir\", default = 'train_output')\n",
    "#     parser.add_argument(\"--test_out_dir\", default = 'test_output')\n",
    "#     parser.add_argument(\"--mode\", default = 'train')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "#     return args\n",
    "\n",
    "\n",
    "class CartoonGAN():\n",
    "    def __init__(self):\n",
    "        self.image_size = 256\n",
    "        self.crop_size = 70\n",
    "        self.batch_size = 8\n",
    "        self.pre_train_iter = 20000\n",
    "        self.iter = 100000\n",
    "        self.learning_rate = 1e-4\n",
    "        self.gpu_fraction = 0.5\n",
    "        self.train_out_dir = 'saved_models'\n",
    "        self.test_out_dir = 'train_output'\n",
    "        self.save_dir = 'test_output'\n",
    "        self.lambda_ = 10\n",
    "        \n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        self.photo_input = tf.placeholder(tf.float32, [None, None, None, 3], name=\"photo\")\n",
    "        self.cartoon_input = tf.placeholder(tf.float32, [None, None, None, 3], name=\"cartoon\")\n",
    "        self.blur_input = tf.placeholder(tf.float32, [None, None, None, 3], name=\"blur\")\n",
    "\n",
    "\n",
    "    \n",
    "    def input_setup(self):\n",
    "        \n",
    "        self.celeba_list = utils.get_filename_list('real_world')\n",
    "        self.cartoon_list = utils.get_filename_list('cartoon_original')\n",
    "        print('Finished loading data')\n",
    "\n",
    "            \n",
    "    def build_model(self):\n",
    "        \n",
    "        self.fake_cartoon = model.generator(self.photo_input, name='generator', \n",
    "                                            reuse=tf.AUTO_REUSE, is_train=self.is_train)\n",
    "#                                             reuse=False, is_train=self.is_train)\n",
    "\n",
    "        self.real_logit_cartoon = model.multi_patch_discriminator(self.cartoon_input, self.crop_size, \n",
    "                                                            name='discriminator', reuse=tf.AUTO_REUSE)    \n",
    "#                                                             name='discriminator', reuse=False)  \n",
    "        \n",
    "        self.fake_logit_cartoon = model.multi_patch_discriminator(self.fake_cartoon, self.crop_size, \n",
    "                                                            name='discriminator', reuse=tf.AUTO_REUSE)  \n",
    "#                                                             name='discriminator', reuse=True)\n",
    "        \n",
    "        self.logit_blur = model.multi_patch_discriminator(self.blur_input, self.crop_size,\n",
    "                                                            name='discriminator', reuse=tf.AUTO_REUSE)  \n",
    "#                                                             name='discriminator', reuse=True)\n",
    "\n",
    "        VGG_loss = utils.vgg_loss(self.photo_input, self.fake_cartoon)\n",
    "        \n",
    "        g_loss = -tf.reduce_mean(tf.log(tf.nn.sigmoid(self.fake_logit_cartoon))) + 5e3*VGG_loss\n",
    "        \n",
    "        d_loss = -tf.reduce_mean(tf.log(tf.nn.sigmoid(self.real_logit_cartoon))\n",
    "                                + tf.log(1. - tf.nn.sigmoid(self.fake_logit_cartoon))\n",
    "                                + tf.log(1. - tf.nn.sigmoid(self.logit_blur)))\n",
    "\n",
    "\n",
    "        all_vars = tf.trainable_variables()\n",
    "\n",
    "        d_vars = [var for var in all_vars if 'discriminator' in var.name]\n",
    "        g_vars = [var for var in all_vars if 'generator' in var.name]\n",
    "\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.init_optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0., beta2=0.9).\\\n",
    "                                        minimize(VGG_loss, var_list=g_vars, colocate_gradients_with_ops=True)\n",
    "            self.d_optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0., beta2=0.9).\\\n",
    "                                        minimize(d_loss, var_list=d_vars, colocate_gradients_with_ops=True)\n",
    "            self.g_optim = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0., beta2=0.9).\\\n",
    "                                        minimize(g_loss, var_list=g_vars, colocate_gradients_with_ops=True)\n",
    "\n",
    "        #Summary variables for tensorboard\n",
    "\n",
    "        self.g_A_loss_summ = tf.summary.scalar('g_loss', g_loss)\n",
    "        self.d_A_loss_summ = tf.summary.scalar('d_loss', d_loss)\n",
    "        self.VGG_loss_summ = tf.summary.scalar('VGG_loss', VGG_loss)\n",
    "        \n",
    "        self.saver = tf.train.Saver(g_vars)\n",
    "        \n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=self.gpu_fraction)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        print('Finished building model')\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        if not os.path.exists(self.train_out_dir):\n",
    "            os.makedirs(self.train_out_dir)\n",
    "        \n",
    "        # Initializing the global variables\n",
    "        init = ([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        train_writer = tf.summary.FileWriter(self.save_dir+\"/train\", self.sess.graph)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            sess = self.sess\n",
    "            sess.run(init)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            print(\"before pre train\")\n",
    "            \n",
    "            # Pre-training iterations\n",
    "            if os.path.isfile(self.save_dir+ '/pre_train-{}.meta'.format(self.pre_train_iter-1)):\n",
    "                self.saver.restore(sess, self.save_dir+ '/pre_train-'+str(self.pre_train_iter-1))\n",
    "                print('Finished loading pre_trained model')\n",
    "            else:\n",
    "                for iter in range(self.pre_train_iter):\n",
    "                    photo_batch = utils.next_batch(self.batch_size, self.image_size, self.celeba_list)\n",
    "                    cartoon_batch, blur_batch = utils.next_blur_batch(self.batch_size, \n",
    "                                                                  self.image_size, \n",
    "                                                                  self.cartoon_list)\n",
    "                \n",
    "                    _ = sess.run([self.init_optim], feed_dict={self.photo_input: photo_batch, \n",
    "                                                                self.cartoon_input: cartoon_batch, \n",
    "                                                                self.blur_input: blur_batch, \n",
    "                                                                self.is_train: True})\n",
    "    \n",
    "                    if np.mod(iter+1, 50) == 0:\n",
    "                        print('pre_train iteration:[%d/%d], time cost:%f' \\\n",
    "                                %(iter+1, self.pre_train_iter, time.time()-start_time))\n",
    "                        start_time = time.time()\n",
    "\n",
    "                        if np.mod(iter+1, 1000) == 0:\n",
    "                            batch_image = sess.run([self.fake_cartoon], \n",
    "                                         feed_dict={self.photo_input: photo_batch, self.is_train: True})\n",
    "                            batch_image = np.squeeze(batch_image)\n",
    "                            utils.print_fused_image(batch_image, self.train_out_dir, str(iter)+'_pre_train.png', 4)\n",
    "                        \n",
    "                        if np.mod(iter+1, self.pre_train_iter) == 0:\n",
    "                            self.saver.save(sess, self.save_dir+ '/pre_train', global_step=iter)\n",
    "                        \n",
    "            print(\"after pre train\")\n",
    "            print(\"before train\")\n",
    "            \n",
    "            #Training iterations\n",
    "            for iter in range(self.iter):                \n",
    "                \n",
    "                photo_batch = utils.next_batch(self.batch_size, self.image_size, self.celeba_list)\n",
    "                cartoon_batch, blur_batch = utils.next_blur_batch(self.batch_size, \n",
    "                                                                  self.image_size, \n",
    "                                                                  self.cartoon_list)\n",
    "                \n",
    "                \n",
    "                _ = sess.run([self.g_optim], feed_dict={self.photo_input: photo_batch, \n",
    "                                                        self.cartoon_input: cartoon_batch, \n",
    "                                                        self.blur_input: blur_batch, \n",
    "                                                        self.is_train: True})\n",
    "\n",
    "                _, summary = sess.run([self.d_optim, summary_op], \n",
    "                                      feed_dict={self.photo_input: photo_batch, \n",
    "                                                self.cartoon_input: cartoon_batch, \n",
    "                                                self.blur_input: blur_batch, \n",
    "                                                self.is_train: True})      \n",
    "\n",
    "                train_writer.add_summary(summary, iter)         \n",
    "                    \n",
    "                if np.mod(iter+1, 10) == 0:\n",
    "                    print('train iteration:[%d/%d], time cost:%f' \\\n",
    "                            %(iter+1, self.iter, time.time()-start_time))\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if np.mod(iter+1, 500) == 0:\n",
    "                        batch_image = sess.run([self.fake_cartoon], \n",
    "                                               feed_dict={self.photo_input: photo_batch, \n",
    "                                                          self.is_train: True})\n",
    "                        batch_image = np.squeeze(batch_image)\n",
    "                        utils.print_fused_image(batch_image, self.train_out_dir, str(iter)+'.png', 4 )\n",
    "                        \n",
    "                    if np.mod(iter+1, 20000) == 0:\n",
    "                        self.saver.save(sess, self.save_dir+ '/model', global_step=iter)\n",
    "                        \n",
    "            print(\"after train\")\n",
    "\n",
    "    def test(self):\n",
    "        \n",
    "        if not os.path.exists(self.test_out_dir):\n",
    "            os.mkdir(self.test_out_dir)\n",
    "        \n",
    "        self.test_list = utils.get_filename_list('actress')\n",
    "        \n",
    "        init = ([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        self.sess.run(init)\n",
    "        self.saver.restore(self.sess, tf.train.latest_checkpoint(self.save_dir)) \n",
    "\n",
    "        for idx in range(100):\n",
    "            photo_batch = utils.next_batch(self.batch_size, self.image_size, self.test_list)\n",
    "            images = self.sess.run([self.fake_cartoon], feed_dict={self.photo_input: photo_batch, \n",
    "                                                                    self.is_train: True})\n",
    "            images = np.squeeze(images)\n",
    "            utils.print_fused_image(images, self.test_out_dir, str(idx)+'.png', 4 )\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "#     args = arg_parser()\n",
    "#     model = CartoonGAN(args)\n",
    "    model = CartoonGAN()\n",
    "    \n",
    "    print(\"train mode test mode\")\n",
    "    mode = 'train'\n",
    "    \n",
    "#     if args.mode == 'train':\n",
    "    if mode == 'train':\n",
    "        model.build_model()\n",
    "        model.input_setup()\n",
    "        model.train()\n",
    "\n",
    "#     elif args.mode == 'test':\n",
    "    elif mode == 'test':\n",
    "        model.build_model()\n",
    "        model.test()\n",
    "    \n",
    "print(\"Log before main function\")\n",
    "    \n",
    "main()\n",
    "\n",
    "print(\"Log after main function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
